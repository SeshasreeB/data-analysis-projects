{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "\n",
                "My dataset:https://www.kaggle.com/datasets/jainaru/world-happiness-report-2024-yearly-updated/data\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "#reading data\n",
                "df = pd.read_csv(r\"C:\\Users\\launchcode\\data-analysis-projects\\World-happiness-report-updated_2024.csv\",encoding='latin1')\n",
                "happy_df = pd.read_csv(r\"C:\\Users\\launchcode\\data-analysis-projects\\World-happiness-report-2024.csv\",encoding='latin1')\n",
                "# Rename 2024 columns to match historical\n",
                "happy_df = happy_df.rename(columns={\n",
                "    \"Ladder score\": \"Life Ladder\",\n",
                "    \"Healthy life expectancy\": \"Healthy life expectancy at birth\"\n",
                "})\n",
                "\n",
                "happy_df[\"year\"]=2024\n",
                "#information about data\n",
                "df.info()\n",
                "happy_df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [],
            "source": [
                "df.isnull()\n",
                "# no null values observed in the columns\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " There are several other columns containing null values. These are:Log GDP per capita,Social support,Healthy life expectancy at birth,Freedom to make life choices,Generosity,Perceptions of corruption,Positive affect,Negative affect "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find all numeric columns and replace any missing values in them with the columnâ€™s average value\n",
                "numeric_cols = df.select_dtypes(include=np.number).columns\n",
                "\n",
                "# not using the code below as that calculates the mean of the column distorting the trend\n",
                "# df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
                "\n",
                "# Fill numeric NaNs with the mean per country\n",
                "df[numeric_cols] = df.groupby('Country name')[numeric_cols].transform(lambda x: x.fillna(x.mean()))\n",
                "\n",
                "# count the number of missing (NaN, None, or NaT) values in each column of a DataFrame \n",
                "df.isnull().sum()\n",
                "# Round all numeric columns to 3 decimal places\n",
                "df[numeric_cols] = df[numeric_cols].round(3)\n",
                "\n",
                "# Preview the first few rows\n",
                "df.head(16)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Missing values in numeric variables were handled by replacing them with the column mean. This ensured no loss of data while preserving overall distributions. Non-numeric columns were left unchanged."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "happy_df.isnull()\n",
                "# no null values observed in the columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "happy_df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = happy_df.select_dtypes(include=np.number).columns\n",
                "happy_df[numeric_cols] = happy_df[numeric_cols].fillna(happy_df[numeric_cols].mean())\n",
                "happy_df[numeric_cols] = happy_df[numeric_cols].round(3)\n",
                "happy_df.tail(50)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Missing values in numeric variables were handled by replacing them with the column mean. This ensured no loss of data while preserving overall distributions. Non-numeric columns were left unchanged."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "happy_df.isnull().sum()\n",
                "happy_df.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(happy_df.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data\n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# target_col = \"Life Ladder\"\n",
                "\n",
                "\n",
                "# plt.figure(figsize=(8, 4))\n",
                "# df[target_col].plot(\n",
                "#     kind=\"hist\",\n",
                "#     bins=25,\n",
                "#     edgecolor=\"black\"\n",
                "# )\n",
                "\n",
                "# plt.title(\"Happiness Score Distribution\")\n",
                "# plt.xlabel(target_col)\n",
                "# plt.ylabel(\"Count\")\n",
                "# plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_col = \"Life Ladder\"\n",
                "\n",
                "top10 = (\n",
                "    df[[\"Country name\", target_col]]\n",
                "    .sort_values(target_col, ascending=False)\n",
                "    .head(10)\n",
                ")\n",
                "bottom10 = (\n",
                "    df[[\"Country name\", target_col]]\n",
                "    .sort_values(target_col, ascending=True)\n",
                "    .head(10)\n",
                ")\n",
                "top10,bottom10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "latest_year = df[\"year\"].max()\n",
                "df_latest = df[df[\"year\"] == latest_year].copy()\n",
                "latest_year, df_latest.shape\n",
                "# target_col = \"Life Ladder\"\n",
                "\n",
                "top10_2023 = (\n",
                "    df_latest[[\"Country name\", target_col]]\n",
                "    .sort_values(target_col, ascending=False)\n",
                "    .head(10)\n",
                ")\n",
                "bottom10_2023 = (\n",
                "    df_latest[[\"Country name\", target_col]]\n",
                "    .sort_values(target_col, ascending=True)\n",
                "    .head(10)\n",
                ")\n",
                "top10_2023,bottom10_2023"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# happy_df = happy_df.copy()\n",
                "# happy_df = happy_df.select_dtypes(include=[\"float64\", \"int64\"])\n",
                "# happy_df.head()\n",
                "numeric_cols = happy_df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
                "\n",
                "# Example: fill NaNs in numeric columns only\n",
                "happy_df[numeric_cols] = happy_df[numeric_cols].fillna(happy_df[numeric_cols].mean())\n",
                "happy_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check number of unique values in key columns (optional sanity check)\n",
                "\n",
                "# happy_df.dtypes\n",
                "# columns = [['Ladder score', 'Log GDP per capita','Social support', 'Healthy life expectancy','Freedom to make life choices','Generosity','Perceptions of corruption']]\n",
                "# for c in columns:\n",
                "#     print(happy_df[c].nunique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "happy_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "happy_df.isna().mean().sort_values(ascending=False) * 100\n",
                "# percentage of missing values in each column of happy_df, sorted from highest to lowest."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = ['Life Ladder', 'Log GDP per capita','Social support']\n",
                "plt.figure(figsize=(8, 6))\n",
                "happy_df[numeric_cols].boxplot()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "social interaction also has  outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "numeric_cols = ['Healthy life expectancy at birth','Freedom to make life choices','Generosity','Perceptions of corruption']\n",
                "plt.figure(figsize=(10, 6))\n",
                "happy_df[numeric_cols].boxplot()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can see that perceptions of corruption has many outliers. Outliers probably reflect genuine socio-economic extremes so I have decided to keep it as removing them will remove the countries as well which are required for this analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [],
            "source": [
                "df.info()\n",
                "#I am using this sheet for reference but if I do end up using this for time-series analysis,  I might drop Positive affect and Negative afect\n",
                "happy_df.info()\n",
                "# I can probably get rid of upper whisker and lower whisker as these are just the upper and lower bounds"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [],
            "source": [
                "happy_df[\"Log GDP per capita\"].value_counts()\n",
                "# There are some low values but they might represent the lower economic countries \n",
                "happy_df[\"Social support\"].value_counts()\n",
                "# there are countries with low social support so outliers like '0' seem valid-Afghanistan\n",
                "happy_df[\"Healthy life expectancy at birth\"].value_counts()\n",
                "# there's one country with 0 value i'm gonna keep it-Lethoso\n",
                "happy_df[\"Freedom to make life choices\"].value_counts()\n",
                "#one country with 0 value -Afghanistan\n",
                "happy_df[\"Generosity\"].value_counts()\n",
                "#ok\n",
                "happy_df[\"Perceptions of corruption\"].value_counts()\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df.columns)\n",
                "print(happy_df.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.dtypes\n",
                "happy_df.dtypes\n",
                "happy_df[\"year\"].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# df.to_csv('world_happiness_yearly_clean.csv', index=False)\n",
                "# happy_df.to_csv('world_happiness_2024_clean.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
